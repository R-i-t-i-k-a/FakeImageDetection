{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Required Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Input, GlobalAveragePooling2D,MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organized\n",
      "Found 100000 validated image filenames belonging to 2 classes.\n",
      "Found 20000 validated image filenames belonging to 2 classes.\n",
      "Found 19999 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\gpu\\lib\\site-packages\\keras\\preprocessing\\image.py:1139: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def limit_data(data_dir, n=100):\n",
    "    data = []\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for idx, filename in enumerate(os.listdir(class_dir)):\n",
    "            if idx >= n:  # Stop when reaching the limit\n",
    "                break\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "            data.append((file_path, class_name))\n",
    "    return pd.DataFrame(data, columns=['filename', 'class'])\n",
    "\n",
    "base_path = 'Dataset2/real_vs_fake/real-vs-fake'\n",
    "image_gen = ImageDataGenerator(rescale=1./255.)\n",
    "batch_size = 32\n",
    "target_size = (224, 224)\n",
    "\n",
    "print(\"Organized\")\n",
    "\n",
    "train_df = limit_data(os.path.join(base_path, 'train'), 50000)\n",
    "valid_df = limit_data(os.path.join(base_path, 'valid'), 10000)\n",
    "test_df = limit_data(os.path.join(base_path, 'test'), 10000)\n",
    "\n",
    "train_flow = image_gen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class\",\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "valid_flow = image_gen.flow_from_dataframe(\n",
    "    dataframe=valid_df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class\",\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_flow = image_gen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col=\"filename\",\n",
    "    y_col=\"class\",\n",
    "    target_size=target_size,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 0, 'real': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flow.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 0, 'real': 1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_flow.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fake': 0, 'real': 1}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flow.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the training and validation loss and accuracy\n",
    "epochs - list of epoch numbers\n",
    "loss - training loss for each epoch\n",
    "val_loss - validation loss for each epoch\n",
    "\"\"\"\n",
    "def plot_loss(epochs, loss, val_loss):\n",
    "    plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'orange', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plot_accuracy(epochs, acc, val_acc):\n",
    "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'orange', label = 'Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine Tune VGGFace Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_WEIGHTS_PATH_NO_TOP = 'https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5'\n",
    "VGGFACE_DIR = 'models/vggface'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def VGG16(input_shape=None):\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_1')(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='conv1_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='conv2_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='conv3_3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv4_3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_1')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='conv5_3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    inputs = img_input\n",
    "    model = Model(inputs, x, name='vggface_vgg16')\n",
    "    model.load_weights('vgg16_weights.h5', by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(input_shape=(224,224,3))\n",
    "# for layers in vgg_model.layers:\n",
    "#     layers.trainable=False\n",
    "last_layer = vgg_model.get_layer('pool5').output\n",
    "flat_layer = GlobalAveragePooling2D()(last_layer)\n",
    "fc1 = Dense(1024, activation='relu', name='fc1')(flat_layer)\n",
    "fc2 = Dense(1024, activation='relu', name='fc2')(fc1)\n",
    "fc3 = Dense(512, activation='relu', name='fc3')(fc2)\n",
    "dense2 = Dense(2, activation='sigmoid', name='dense2')(fc3)\n",
    "model = Model(vgg_model.input, dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 224, 224, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv1_2 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 224, 224, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv2_1 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 112, 112, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2_2 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 112, 112, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv3_1 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 56, 56, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3_2 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 56, 56, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv3_3 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 56, 56, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool3 (MaxPooling2D)        (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv4_1 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 28, 28, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_2 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 28, 28, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv4_3 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 28, 28, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool4 (MaxPooling2D)        (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv5_1 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_2 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv5_3 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " pool5 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 1024)              525312    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 1024)              1049600   \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 512)               524800    \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,832,322\n",
      "Trainable params: 16,823,874\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    metrics=['acc'],\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_df)//batch_size\n",
    "valid_steps = len(valid_df)//batch_size\n",
    "filepath_model = \"model_vggface.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath_model, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit(train_flow,\n",
    "                    steps_per_epoch=train_steps, \n",
    "                    validation_data=valid_flow,\n",
    "                    validation_steps=valid_steps,\n",
    "                    epochs=1,\n",
    "                    verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('vggface.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(range(1, len(loss) + 1), loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracy(range(1, len(loss) + 1), acc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999/19999 [==============================] - 331s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_flow)\n",
    "y_test = test_flow.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.9507499699969998\n",
      "AP Score: 0.9105263730357516\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     10000\n",
      "           1       0.91      1.00      0.95      9999\n",
      "\n",
      "    accuracy                           0.95     19999\n",
      "   macro avg       0.96      0.95      0.95     19999\n",
      "weighted avg       0.96      0.95      0.95     19999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x=np.argmax(y_pred,axis=1)\n",
    "print(\"ROC-AUC Score:\", metrics.roc_auc_score(y_test, x))\n",
    "print(\"AP Score:\", metrics.average_precision_score(y_test, x))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, x > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
